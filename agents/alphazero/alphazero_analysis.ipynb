{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_game_state(encoded_obs):\n",
    "    # Define game parameters\n",
    "    num_colors = 5   # R, Y, G, W, B\n",
    "    num_ranks = 5    # 1 to 5\n",
    "    num_players = 2\n",
    "    hand_size = 5\n",
    "    bits_per_card = num_colors * num_ranks  # 25\n",
    "    max_deck_size = 50\n",
    "    max_information_tokens = 8\n",
    "    max_life_tokens = 3\n",
    "\n",
    "    # Helper functions\n",
    "    def card_index(color, rank):\n",
    "        return color * num_ranks + rank\n",
    "\n",
    "    def get_color_rank_from_index(index):\n",
    "        color = index // num_ranks\n",
    "        rank = index % num_ranks\n",
    "        return color, rank\n",
    "\n",
    "    colors = ['R', 'Y', 'G', 'W', 'B']\n",
    "    ranks = ['1', '2', '3', '4', '5']\n",
    "\n",
    "    # Initialize offsets\n",
    "    offset = 0\n",
    "    encoding = encoded_obs\n",
    "\n",
    "    # --- Hands Section ---\n",
    "    hands_section_length = (num_players - 1) * hand_size * bits_per_card + num_players\n",
    "    hands = []\n",
    "    hand_sizes = [hand_size] * num_players  # Initialize hand sizes for all players\n",
    "\n",
    "    # Other players' hands\n",
    "    for player in range(1, num_players):\n",
    "        player_hand = []\n",
    "        num_cards_in_hand = hand_size\n",
    "        for card_idx in range(num_cards_in_hand):\n",
    "            card_offset = offset + card_idx * bits_per_card\n",
    "            card_bits = encoding[card_offset:card_offset + bits_per_card]\n",
    "            if any(card_bits):\n",
    "                card_pos = card_bits.index(1)\n",
    "                color_idx, rank_idx = get_color_rank_from_index(card_pos)\n",
    "                card_str = f\"{colors[color_idx]}{ranks[rank_idx]}\"\n",
    "            else:\n",
    "                card_str = \"XX\"\n",
    "            player_hand.append(card_str)\n",
    "        hands.append(player_hand)\n",
    "\n",
    "    offset += (num_players - 1) * hand_size * bits_per_card\n",
    "\n",
    "    # Missing card indicators\n",
    "    missing_card_bits = encoding[offset:offset + num_players]\n",
    "    missing_cards = [bool(bit) for bit in missing_card_bits]\n",
    "    offset += num_players\n",
    "\n",
    "    # Adjust hand sizes based on missing cards\n",
    "    for idx, missing in enumerate(missing_cards):\n",
    "        if missing:\n",
    "            hand_sizes[idx] -= 1  # Assume one card is missing\n",
    "\n",
    "    # --- Board Section ---\n",
    "    # Deck size (thermometer encoding)\n",
    "    deck_size_bits = encoding[offset:offset + (max_deck_size - num_players * hand_size)]\n",
    "    deck_size = sum(deck_size_bits)\n",
    "    offset += (max_deck_size - num_players * hand_size)\n",
    "\n",
    "    # Fireworks\n",
    "    fireworks = []\n",
    "    for color_idx in range(num_colors):\n",
    "        firework_bits = encoding[offset:offset + num_ranks]\n",
    "        if any(firework_bits):\n",
    "            highest_rank = firework_bits.index(1) + 1  # Ranks are 1-indexed\n",
    "        else:\n",
    "            highest_rank = 0\n",
    "        fireworks.append(f\"{colors[color_idx]}{highest_rank}\")\n",
    "        offset += num_ranks\n",
    "\n",
    "    # Information tokens (thermometer encoding)\n",
    "    info_token_bits = encoding[offset:offset + max_information_tokens]\n",
    "    info_tokens = sum(info_token_bits)\n",
    "    offset += max_information_tokens\n",
    "\n",
    "    # Life tokens (thermometer encoding)\n",
    "    life_token_bits = encoding[offset:offset + max_life_tokens]\n",
    "    life_tokens = sum(life_token_bits)\n",
    "    offset += max_life_tokens\n",
    "\n",
    "    # --- Discards Section ---\n",
    "    discard_bits = encoding[offset:offset + max_deck_size]\n",
    "    offset += max_deck_size\n",
    "\n",
    "    # Reconstruct discard pile\n",
    "    discards = []\n",
    "    idx_in_discard = 0\n",
    "    for color_idx in range(num_colors):\n",
    "        for rank_idx in range(num_ranks):\n",
    "            num_instances = 0\n",
    "            if rank_idx == 0:\n",
    "                num_instances = 3\n",
    "            elif rank_idx == 4:\n",
    "                num_instances = 1\n",
    "            else:\n",
    "                num_instances = 2\n",
    "            for i in range(num_instances):\n",
    "                if discard_bits[idx_in_discard] == 1:\n",
    "                    discards.append(f\"{colors[color_idx]}{ranks[rank_idx]}\")\n",
    "                idx_in_discard += 1\n",
    "\n",
    "    # --- Last Action Section ---\n",
    "    last_action_section_length = (\n",
    "        num_players + 4 + num_players + num_colors + num_ranks +\n",
    "        hand_size + hand_size + bits_per_card + 2\n",
    "    )\n",
    "    offset += last_action_section_length\n",
    "\n",
    "    # --- Card Knowledge Section ---\n",
    "    card_knowledge_section_length = num_players * hand_size * (bits_per_card + num_colors + num_ranks)\n",
    "    card_knowledge = []\n",
    "\n",
    "    for player in range(num_players):\n",
    "        player_card_knowledge = []\n",
    "        num_cards_in_hand = hand_sizes[player]\n",
    "        for card_idx in range(hand_size):\n",
    "            if card_idx >= num_cards_in_hand:\n",
    "                # Skip missing cards\n",
    "                offset += bits_per_card + num_colors + num_ranks\n",
    "                continue\n",
    "\n",
    "            # Plausible cards\n",
    "            plausible_cards_bits = encoding[offset:offset + bits_per_card]\n",
    "            offset += bits_per_card\n",
    "\n",
    "            # Revealed colors\n",
    "            revealed_color_bits = encoding[offset:offset + num_colors]\n",
    "            offset += num_colors\n",
    "\n",
    "            # Revealed ranks\n",
    "            revealed_rank_bits = encoding[offset:offset + num_ranks]\n",
    "            offset += num_ranks\n",
    "\n",
    "            # Determine plausible colors and ranks\n",
    "            plausible_colors = set()\n",
    "            plausible_ranks = set()\n",
    "            for idx_pc, bit in enumerate(plausible_cards_bits):\n",
    "                if bit == 1:\n",
    "                    color_idx, rank_idx = get_color_rank_from_index(idx_pc)\n",
    "                    plausible_colors.add(colors[color_idx])\n",
    "                    plausible_ranks.add(ranks[rank_idx])\n",
    "\n",
    "            # Determine explicitly revealed colors and ranks\n",
    "            revealed_colors = [colors[i] for i, bit in enumerate(revealed_color_bits) if bit == 1]\n",
    "            revealed_ranks = [ranks[i] for i, bit in enumerate(revealed_rank_bits) if bit == 1]\n",
    "\n",
    "            card_knowledge_entry = {\n",
    "                'plausible_colors': plausible_colors,\n",
    "                'plausible_ranks': plausible_ranks,\n",
    "                'revealed_colors': revealed_colors,\n",
    "                'revealed_ranks': revealed_ranks,\n",
    "            }\n",
    "            player_card_knowledge.append(card_knowledge_entry)\n",
    "\n",
    "        card_knowledge.append(player_card_knowledge)\n",
    "\n",
    "    # --- Construct Output String ---\n",
    "    output = []\n",
    "\n",
    "    output.append(f\"Information Tokens: {info_tokens}\")\n",
    "    output.append(f\"Life Tokens: {life_tokens}\")\n",
    "    output.append(\"Fireworks: \" + ' '.join(fireworks))\n",
    "    output.append(f\"Deck size: {deck_size}\")\n",
    "    output.append(\"Discards:\")\n",
    "    if discards:\n",
    "        output.append(' '.join(discards))\n",
    "    else:\n",
    "        output.append(\"None\")\n",
    "\n",
    "    output.append(\"\\nHands:\")\n",
    "    # Your hand with card knowledge\n",
    "    output.append(\"Your hand:\")\n",
    "    your_hand_str = []\n",
    "    for card_idx in range(hand_size):\n",
    "        if card_idx >= len(card_knowledge[0]):\n",
    "            continue  # Skip missing cards\n",
    "\n",
    "        card_knowledge_entry = card_knowledge[0][card_idx]  # Our own hand is player 0\n",
    "\n",
    "        # Determine known color and rank\n",
    "        known_color = 'X'\n",
    "        if len(card_knowledge_entry['revealed_colors']) == 1:\n",
    "            known_color = card_knowledge_entry['revealed_colors'][0]\n",
    "\n",
    "        known_rank = 'X'\n",
    "        if len(card_knowledge_entry['revealed_ranks']) == 1:\n",
    "            known_rank = card_knowledge_entry['revealed_ranks'][0]\n",
    "\n",
    "        # Build plausible colors and ranks strings\n",
    "        plausible_colors_str = ''.join(sorted(card_knowledge_entry['plausible_colors'], key=lambda x: colors.index(x)))\n",
    "        plausible_ranks_str = ''.join(sorted(card_knowledge_entry['plausible_ranks'], key=lambda x: ranks.index(x)))\n",
    "\n",
    "        # If no plausible colors or ranks, show all\n",
    "        if not plausible_colors_str:\n",
    "            plausible_colors_str = ''.join(colors)\n",
    "        if not plausible_ranks_str:\n",
    "            plausible_ranks_str = ''.join(ranks)\n",
    "\n",
    "        # Format the card knowledge as per your requirement\n",
    "        card_str = f\"{known_color}{known_rank} || {plausible_colors_str}{plausible_ranks_str}\"\n",
    "        your_hand_str.append(card_str)\n",
    "\n",
    "    output.extend(your_hand_str)\n",
    "\n",
    "    # Other player's hand\n",
    "    output.append(\"\\nOther player's hand:\")\n",
    "    other_hand = hands[0]\n",
    "    other_hand_str = ' '.join(other_hand)\n",
    "    if missing_cards[1]:\n",
    "        other_hand_str += \" (missing cards)\"\n",
    "    output.append(other_hand_str)\n",
    "\n",
    "    # Return the output string\n",
    "    return '\\n'.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data interpretation complete. Results saved in 'interpret_data' file.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "# Initialize lists to store data\n",
    "data = []\n",
    "moves = [\n",
    "    {'action_type': 'DISCARD', 'card_index': 0},\n",
    "    {'action_type': 'DISCARD', 'card_index': 1},\n",
    "    {'action_type': 'DISCARD', 'card_index': 2},\n",
    "    {'action_type': 'DISCARD', 'card_index': 3},\n",
    "    {'action_type': 'DISCARD', 'card_index': 4},\n",
    "    {'action_type': 'PLAY', 'card_index': 0},\n",
    "    {'action_type': 'PLAY', 'card_index': 1},\n",
    "    {'action_type': 'PLAY', 'card_index': 2},\n",
    "    {'action_type': 'PLAY', 'card_index': 3},\n",
    "    {'action_type': 'PLAY', 'card_index': 4},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'R'},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'Y'},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'G'},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'W'},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'B'},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 0},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 1},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 2},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 3},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 4}\n",
    "]\n",
    "\n",
    "# Read and parse the data from the 'alphazero_data.txt' text file\n",
    "with open('alphazero_data.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Updated regex to capture the new data format with the root policy\n",
    "tuple_strings = re.findall(\n",
    "    r'\\(tensor\\(\\[([\\s\\S]*?)\\]\\),\\s*'    # Encoded observation\n",
    "    r'tensor\\(\\[([\\s\\S]*?)\\]\\),\\s*'      # Policy\n",
    "    r'tensor\\(([\\s\\S]*?)\\),\\s*'          # Value\n",
    "    r'tensor\\(\\[([\\s\\S]*?)\\]\\)\\)',       # Root policy\n",
    "    content, re.DOTALL\n",
    ")\n",
    "\n",
    "# Process each tuple string\n",
    "for encoded_obs_str, policy_str, value_str, root_policy_str in tuple_strings:\n",
    "    # Clean and process the encoded observation\n",
    "    encoded_obs_list = [float(x.strip()) for x in encoded_obs_str.strip().split(',')]\n",
    "    # Clean and process the policy (MCTS policy)\n",
    "    policy_list = [float(x.strip()) for x in policy_str.strip().split(',')]\n",
    "    # Clean and process the value outcome\n",
    "    value_outcome = float(value_str.strip())\n",
    "    # Clean and process the root policy\n",
    "    root_policy_list = [float(x.strip()) for x in root_policy_str.strip().split(',')]\n",
    "\n",
    "    # Append to data list\n",
    "    data.append((encoded_obs_list, policy_list, value_outcome, root_policy_list))\n",
    "\n",
    "# Open the output file 'interpret_data' for writing\n",
    "with open('interpret_data', 'w') as output_file:\n",
    "    # Process each tuple in the data\n",
    "    for idx, (encoded_obs_list, policy_list, value_outcome, root_policy_list) in enumerate(data):\n",
    "        # Reconstruct the game state\n",
    "        game_state_str = reconstruct_game_state(encoded_obs_list)\n",
    "        # Get the value outcome\n",
    "        value = value_outcome\n",
    "\n",
    "        # Find the index/indices of the action(s) with the highest MCTS probability\n",
    "        max_prob = max(policy_list)\n",
    "        max_prob_indices = [i for i, prob in enumerate(policy_list) if prob == max_prob]\n",
    "\n",
    "        # Find the index/indices of the action(s) with the highest root policy probability\n",
    "        max_root_prob = max(root_policy_list)\n",
    "        max_root_prob_indices = [i for i, prob in enumerate(root_policy_list) if prob == max_root_prob]\n",
    "\n",
    "        # Write the results to the output file\n",
    "        output_file.write(f\"{'='*76}\\n\")\n",
    "        output_file.write(f\"Game State {idx+1}\\n\")\n",
    "        output_file.write(f\"{'='*76}\\n\\n\")\n",
    "\n",
    "        output_file.write(\"Game State Details:\\n\")\n",
    "        output_file.write(f\"{'-'*76}\\n\")\n",
    "        output_file.write(game_state_str + '\\n\\n')\n",
    "\n",
    "        # Write the moves and corresponding policy probabilities in a table format\n",
    "        output_file.write(\"Moves and Policy Probabilities:\\n\")\n",
    "        output_file.write(f\"{'-'*76}\\n\")\n",
    "        output_file.write(f\"{'Move Description':<50} {'MCTS Prob':>12} {'Root Policy':>12}\\n\")\n",
    "        output_file.write(f\"{'-'*50}{'-'*13}{'-'*13}\\n\")\n",
    "        for i, (move, prob, root_prob) in enumerate(zip(moves, policy_list, root_policy_list)):\n",
    "            # Format the move description\n",
    "            if move['action_type'] == 'DISCARD' or move['action_type'] == 'PLAY':\n",
    "                move_desc = f\"{move['action_type']} card at index {move['card_index']}\"\n",
    "            elif move['action_type'] == 'REVEAL_COLOR':\n",
    "                move_desc = f\"REVEAL_COLOR {move['color']} to player {move['target_offset']}\"\n",
    "            elif move['action_type'] == 'REVEAL_RANK':\n",
    "                move_desc = f\"REVEAL_RANK {move['rank'] + 1} to player {move['target_offset']}\"\n",
    "            else:\n",
    "                move_desc = f\"Unknown move type: {move['action_type']}\"\n",
    "\n",
    "            # Initialize the marker for this move\n",
    "            marker = '  '\n",
    "\n",
    "            # Check if this is the action with the highest MCTS probability\n",
    "            if i in max_prob_indices:\n",
    "                marker = '* '\n",
    "            # Check if this is the action with the highest root policy probability\n",
    "            if i in max_root_prob_indices:\n",
    "                if marker.strip():\n",
    "                    # If already marked (i.e., both max MCTS and max root policy)\n",
    "                    marker = '*^'\n",
    "                else:\n",
    "                    marker = '^ '\n",
    "\n",
    "            output_file.write(f\"{marker}{move_desc:<48} {prob:>12.4f} {root_prob:>12.4f}\\n\")\n",
    "        output_file.write('\\n')\n",
    "        output_file.write(f\"Value Outcome: {value:.4f}\\n\")\n",
    "        output_file.write(f\"{'='*76}\\n\\n\\n\")\n",
    "\n",
    "print(\"Data interpretation complete. Results saved in 'interpret_data' file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the mass is in one action and the rest is 0. \n",
    "MCTS without rules with 1000 rollouts => 8.3 for 10 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data interpretation complete. Results saved in 'interpret_mcts_data' file.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Initialize lists to store data\n",
    "data = []\n",
    "moves = [\n",
    "    {'action_type': 'DISCARD', 'card_index': 0},\n",
    "    {'action_type': 'DISCARD', 'card_index': 1},\n",
    "    {'action_type': 'DISCARD', 'card_index': 2},\n",
    "    {'action_type': 'DISCARD', 'card_index': 3},\n",
    "    {'action_type': 'DISCARD', 'card_index': 4},\n",
    "    {'action_type': 'PLAY', 'card_index': 0},\n",
    "    {'action_type': 'PLAY', 'card_index': 1},\n",
    "    {'action_type': 'PLAY', 'card_index': 2},\n",
    "    {'action_type': 'PLAY', 'card_index': 3},\n",
    "    {'action_type': 'PLAY', 'card_index': 4},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'R'},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'Y'},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'G'},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'W'},\n",
    "    {'action_type': 'REVEAL_COLOR', 'target_offset': 1, 'color': 'B'},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 0},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 1},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 2},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 3},\n",
    "    {'action_type': 'REVEAL_RANK', 'target_offset': 1, 'rank': 4}\n",
    "]\n",
    "\n",
    "# Read and parse the data from the 'alphazero_data.txt' text file\n",
    "with open('../mcts/mcts_data.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Split the content into individual entries\n",
    "# This regex matches each complete data entry\n",
    "entry_pattern = re.compile(\n",
    "    r'\\(tensor\\(\\[([\\s\\S]*?)\\]\\),\\s*'     # Encoded observation\n",
    "    r'tensor\\(\\[([\\s\\S]*?)\\]\\),\\s*'       # Policy A\n",
    "    r'tensor\\(\\[([\\s\\S]*?)\\]\\),\\s*'       # Policy B\n",
    "    r'tensor\\(([\\s\\S]*?)\\)\\)\\s*',         # Value\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "entries = entry_pattern.findall(content)\n",
    "\n",
    "# Process each entry\n",
    "for encoded_obs_str, policy_a_str, policy_b_str, value_str in entries:\n",
    "    # Clean and process the encoded observation\n",
    "    encoded_obs_list = [float(x.strip()) for x in re.split(r',\\s*', encoded_obs_str.strip()) if x.strip()]\n",
    "    # Clean and process Policy A\n",
    "    policy_a_list = [float(x.strip()) for x in re.split(r',\\s*', policy_a_str.strip()) if x.strip()]\n",
    "    # Clean and process Policy B\n",
    "    policy_b_list = [float(x.strip()) for x in re.split(r',\\s*', policy_b_str.strip()) if x.strip()]\n",
    "    # Clean and process the value outcome\n",
    "    value_outcome = float(value_str.strip())\n",
    "\n",
    "    # Append to data list\n",
    "    data.append((encoded_obs_list, policy_a_list, policy_b_list, value_outcome))\n",
    "\n",
    "# Open the output file 'interpret_mcts_data' for writing\n",
    "with open('interpret_mcts_data', 'w') as output_file:\n",
    "    # Process each tuple in the data\n",
    "    for idx, (encoded_obs_list, policy_a_list, policy_b_list, value_outcome) in enumerate(data):\n",
    "        # Reconstruct the game state\n",
    "        game_state_str = reconstruct_game_state(encoded_obs_list)\n",
    "        # Get the value outcome\n",
    "        value = value_outcome\n",
    "\n",
    "        # Find the index/indices of the action(s) with the highest probability in Policy A\n",
    "        max_prob_a = max(policy_a_list)\n",
    "        max_prob_a_indices = [i for i, prob in enumerate(policy_a_list) if prob == max_prob_a]\n",
    "\n",
    "        # Find the index/indices of the action(s) with the highest probability in Policy B\n",
    "        max_prob_b = max(policy_b_list)\n",
    "        max_prob_b_indices = [i for i, prob in enumerate(policy_b_list) if prob == max_prob_b]\n",
    "\n",
    "        # Write the results to the output file\n",
    "        output_file.write(f\"{'='*76}\\n\")\n",
    "        output_file.write(f\"Game State {idx+1}\\n\")\n",
    "        output_file.write(f\"{'='*76}\\n\\n\")\n",
    "\n",
    "        output_file.write(\"Game State Details:\\n\")\n",
    "        output_file.write(f\"{'-'*76}\\n\")\n",
    "        output_file.write(game_state_str + '\\n\\n')\n",
    "\n",
    "        # Write the moves and corresponding policy probabilities in a table format\n",
    "        output_file.write(\"Moves and Policy Probabilities:\\n\")\n",
    "        output_file.write(f\"{'-'*76}\\n\")\n",
    "        output_file.write(f\"{'Move Description':<50} {'Policy A':>12} {'Policy B':>12}\\n\")\n",
    "        output_file.write(f\"{'-'*50}{'-'*13}{'-'*13}\\n\")\n",
    "        for i, (move, prob_a, prob_b) in enumerate(zip(moves, policy_a_list, policy_b_list)):\n",
    "            # Format the move description\n",
    "            if move['action_type'] == 'DISCARD' or move['action_type'] == 'PLAY':\n",
    "                move_desc = f\"{move['action_type']} card at index {move['card_index']}\"\n",
    "            elif move['action_type'] == 'REVEAL_COLOR':\n",
    "                move_desc = f\"REVEAL_COLOR {move['color']} to player {move['target_offset']}\"\n",
    "            elif move['action_type'] == 'REVEAL_RANK':\n",
    "                move_desc = f\"REVEAL_RANK {move['rank'] + 1} to player {move['target_offset']}\"\n",
    "            else:\n",
    "                move_desc = f\"Unknown move type: {move['action_type']}\"\n",
    "\n",
    "            # Initialize the marker for this move\n",
    "            marker = '  '\n",
    "\n",
    "            # Check if this is the action with the highest probability in Policy A\n",
    "            if i in max_prob_a_indices:\n",
    "                marker = '* '\n",
    "            # Check if this is the action with the highest probability in Policy B\n",
    "            if i in max_prob_b_indices:\n",
    "                if marker.strip():\n",
    "                    marker = '*^'\n",
    "                else:\n",
    "                    marker = '^ '\n",
    "\n",
    "            output_file.write(f\"{marker}{move_desc:<48} {prob_a:>12.4f} {prob_b:>12.4f}\\n\")\n",
    "        output_file.write('\\n')\n",
    "        output_file.write(f\"Value Outcome: {value:.4f}\\n\")\n",
    "        output_file.write(f\"{'='*76}\\n\\n\\n\")\n",
    "\n",
    "print(\"Data interpretation complete. Results saved in 'interpret_mcts_data' file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(hanabi) kaanucar@MacBook-Pro-de-Kaan hanabi_epfl % python rl_env_example.py --players 2 --num_episodes 10 --agent AlphaZero_Agent --agents AlphaZero_Agent --mcts_types 00\n",
    "Running Episodes:   0%|                                                                                         | 0/10 [00:00<?, ?episode/s, Avg Score=N/A, Score=N/A, Avg Loss=N/A, Loss=N/A]/Users/kaanucar/Desktop/hanabi_epfl/agents/alphazero/alphazero_network.py:172: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "  root_policy = torch.tensor(root_policy, dtype=torch.float32)\n",
    "Running Episodes: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [21:39<00:00, 129.92s/episode, Avg Score=17.10, Score=17, Avg Loss=2.9694, Loss=2.9340]\n",
    "\n",
    "Losses:  ['3.03', '3.01', '2.99', '2.98', '2.97', '2.93', '2.94', '2.95', '2.93']\n",
    "Average Loss:  2.969351159201728\n",
    "\n",
    "Scores: [18, 19, 17, 17, 13, 17, 16, 17, 20, 17]\n",
    "Average Score: 17.1\n",
    "Standard Deviation: 1.7578395831246947\n",
    "Standard Error: 0.5558776843874919\n",
    "Errors: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanabi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
